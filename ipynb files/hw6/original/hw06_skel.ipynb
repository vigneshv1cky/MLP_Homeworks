{"cells": [{"cell_type": "markdown", "metadata": {"editable": true, "id": "wWsdiIFTd6rc", "slideshow": {"slide_type": ""}, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "source": ["NAME: __TODO: FULLNAME__\n", "\n", "# Machine Learning Practice - Asynchronous\n", "## Homework 06: Cross Validation\n", "\n", "## Assignment Overview\n", "Read through the entire notebook & do not write any code. This assignment\n", "is more complex than previous ones, and it will be helpful to have a sense of \n", "the structure before you start coding.  \n", "\n", "\n", "### Task\n", "For this assignment you will be implementing __holistic cross-validation__. \n", "Cross-validation is a procedure for performing statistically sound training \n", "and evaluation of models when you have limited amounts of data.  In addition,\n", "we are using it to select hyper-parameters and to understand the interaction \n", "between hyper-parameter choices and training set size.\n", "\n", "The three data sets are used as follows:\n", "*  Training set: used to train the parameters of the various models\n", "*  Validation set: used to evaluate and select the best performing model hyper-parameter set, and\n", "*  Testing set: used to perform evaluation of the selected models (but only after hyper-parameters\n", "are selected!).\n", "\n", "On top of cross-validation, we will be experimenting with differently sized training sets and \n", "different sets of hyper-parameters for your model.  This means that we will be executing a \n", "3D grid of experiments that is indexed by:\n", "1. Rotation\n", "2. Hyper-parameter set\n", "3. Training set size\n", "\n", "Each of the experiments in the grid involves the training and evaluation of a model, as well as collating these results into a form through which it is easy to identify the ideal hyper-parameters for a given training set size.  Specifically, for each training set size, we will select the one hyper-parameter set that maximizes the mean validation performance (across the rotations).  Once a hyper-parameter set is chosen, we will then examine the mean test set performance (again, for each training set size).\n", "\n", "### Data set\n", "The dataset is identical to what we used in HW05\n", "\n", "### Objectives\n", "* Implement and understand __Holistic Cross Validation__\n", "* Perform a training set size sensitivity analysis and observe how hyper-parameter choices change with training set size\n", "\n", "### Instructions\n", "* All Homework must be individual work.  Do not look at or copy solutions of other students or that are available on the Internet or via LLMs\n", "* Only work in a copy of the file that is from your ~/homework_in/ directory\n", "   + If you do not use your own copy of this file, then it is an automatic zero on the assignment\n", "* Read the code below \n", "* For any cell that is flagged as *TODO*, complete the code according to the specifications\n", "* Execute each cell and verify that it is showing correct results.  Note that because we are reusing variables, the order of execution is *really* important (you should code assuming top to bottom execution).\n", "* All the plotting functions have been provided. You should not need to alter any of these.\n", "* Hand-In Procedure\n", "  + Make sure that your notebook has been saved.  You are responsible for ensuring that the copy that you submit is current and complete\n", "  + The name of the file should be the same as what we gave you\n", "  + Download this file to your local machine (extension: .ipynb)\n", "  + Submit to the Gradescope Notebook HW06 dropbox\n", "\n", "\n", "### General References\n", "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n", "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n", "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n", "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n", "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n", "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n", "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n", "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n", "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/api/sklearn.linear_model.html)\n", "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/api/sklearn.model_selection.html)\n", "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/api/sklearn.ensemble.html)\n", "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/api/sklearn.metrics.html)\n", "* [JobLib](https://joblib.readthedocs.io/en/latest/)\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"editable": true, "id": "DtEpd7j6d6rg", "slideshow": {"slide_type": ""}, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import pickle as pkl\n", "import scipy.stats as stats\n", "import os, re, fnmatch\n", "import pathlib, itertools, time\n", "import matplotlib.pyplot as plt\n", "import joblib\n", "import random\n", "\n", "from sklearn.model_selection import cross_val_score, cross_val_predict\n", "from sklearn.metrics import explained_variance_score\n", "from sklearn import metrics\n", "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n", "\n", "# Default figure parameters\n", "plt.rcParams['figure.figsize'] = (8,5)\n", "plt.rcParams['font.size'] = 12\n", "plt.rcParams['legend.fontsize'] = 12\n", "plt.rcParams['xtick.labelsize'] = 12\n", "plt.rcParams['ytick.labelsize'] = 12\n", "plt.rcParams['figure.constrained_layout.use'] = True\n", "plt.rcParams['axes.titlesize'] = 18\n", "plt.rcParams['axes.labelsize'] = 14\n", "\n", "%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {"id": "-McDJZk8d6rj", "wm": "ApccFt0MQeI72fjy"}, "source": ["# LOAD DATA"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "27_0NQCvd6rk", "outputId": "448cb63a-58dd-446d-82a2-7a74599751ba", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED\n", "Load the BMI data from all the folds\n", "\"\"\"\n", "fname = '/mlp/datasets/bmi/bmi_dataset.pkl'\n", "\n", "with open(fname, 'rb') as f:\n", "    bmi = pkl.load(f)\n", "\n", "    MI_folds = bmi['MI'] \n", "    theta_folds = bmi['theta']\n", "    dtheta_folds = bmi['dtheta']\n", "    ddtheta_folds = bmi['ddtheta']\n", "    torque_folds = bmi['torque']\n", "    time_folds = bmi['time']\n", "\n", "\n", "nfolds = len(MI_folds)\n", "nfolds"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "B642OrHqd6ro", "outputId": "8b209a0e-c83c-4f0b-acda-7a4794f51f08", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED: EXECUTE CELL\n", "For this homework, we will be generating many different data sets to \n", "train/validate/test many different models. It is rather problematic to \n", "to work with individual folds of different length, because numpy \n", "cannot efficiently concatenate them together  \n", "\n", "Here, we construct a single unified array for each of our data types.  folds_idx\n", "is a list (1) of lists (2).  List (1) contains one element for each fold; list (2) \n", "for a given fold is a list of indices in the in the unified array for *that* fold.\n", "This allows us to efficiently index into our data instead of creating a copy of it each time we want to \n", "change the size of the training set or our cross-validation rotation.\n", "\"\"\"\n", "\n", "# Starting index for each fold\n", "folds_idx = [None]*nfolds\n", "\n", "unified_idx = 0\n", "for i, fold in enumerate(time_folds):\n", "    # creates a list containing indexes from start of fold to end of fold,\n", "    # eg folds_idx[0] = [0,1,...,1192], folds_idx[1] = [1193,...,2296], ...\n", "    # we don't need to store all this (could just store start indices),\n", "    # but this makes it a lot easier later\n", "    folds_idx[i] = list(range(unified_idx, unified_idx + fold.shape[0]))\n", "    unified_idx += fold.shape[0]\n", "\n", "def concat_folds(folds):\n", "    return np.concatenate(folds, axis=0)\n", "\n", "# These variables contain *ALL* of the data\n", "MI = concat_folds(MI_folds) \n", "theta = concat_folds(theta_folds)\n", "dtheta = concat_folds(dtheta_folds)\n", "ddtheta = concat_folds(ddtheta_folds)\n", "torque = concat_folds(torque_folds)\n", "time = concat_folds(time_folds)\n", "\n", "# Sizes of the entire data set\n", "print(MI.shape, theta.shape, dtheta.shape, ddtheta.shape, torque.shape, time.shape)\n", "\n", "# Starting index of each fold in the full data set\n", "[folds_idx[i][0] for i in range(nfolds)]"]}, {"cell_type": "markdown", "metadata": {"id": "lEQ9e1dLd6rp", "wm": "ApccFt0MQeI72fjy"}, "source": ["# PARAMETER SET LIST"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "iA0CcLFSd6rr", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED: EXECUTE CELL\n", "\n", "Construct the Cartesian product of the provided hyper-parameters (a Cartesian\n", "product of two sets is all possible combinations of elements drawn from each set).\n", "\n", "Note that one can also include hyper-parameters in the list with only a single\n", "option.  This has the effect of simply setting the same hyper-parameter value for each\n", "of resulting hyper-parameter sets.\n", "\n", "\"\"\"\n", "def generate_paramsets(param_lists):\n", "    '''\n", "    Construct the Cartesian product of the parameters\n", "    PARAMS:\n", "        params_lists: dict of lists of values to try for each parameter.\n", "                      keys of the dict are the names of the hyper-parameters.\n", "                      values are lists of possible values to try for the \n", "                      corresponding hyper-parameter\n", "    RETURNS: a list of dicts of hyper-parameter sets.  These make up the \n", "    Cartesian product of the possible hyper-parameters\n", "    '''\n", "    keys, values = zip(*param_lists.items())\n", "    \n", "    # Determines Cartesian product of parameter values\n", "    combos = itertools.product(*values)\n", "    \n", "    # Constructs list of dictionaries\n", "    combos_dicts = [dict(zip(keys, vals)) for vals in combos]\n", "    return list(combos_dicts)"]}, {"cell_type": "markdown", "metadata": {"id": "9NskWaATd6rs", "wm": "ApccFt0MQeI72fjy"}, "source": ["# PERFORMANCE EVALUTION\n", "Tools for evaluating models"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "cmGUQ1R_d6rt", "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED\n", "Evaluate the performance of an already trained model\n", "\n", "\"\"\"\n", "\n", "def predict_score_eval(model, X, y, convert_deg=False):\n", "    '''\n", "    \n", "    Compute the model predictions and cooresponding scores.\n", "    PARAMS:\n", "        model: the trained model used to make predicitons\n", "        X: feature data (MxN)\n", "        y: desired output (Mxk)\n", "        convert_deg: Boolean flag to indicate whether rmse should be\n", "            converted from rad to deg\n", "            \n", "    RETURNS:\n", "        mse: mean squared error for each column (k vector)\n", "        rmse: rMSE (k vector)\n", "        fvaf: fraction of variance accounted for metric (k vector)\n", "        preds: predictions made by the model (M x k matrix)\n", "    '''\n", "    # use the model to predict the outputs from the input data\n", "    preds = model.predict(X) \n", "    \n", "\n", "    # Compute VAR/MSE/RMSE\n", "    mse = np.sum(np.square(y - preds), axis=0) / y.shape[0] \n", "    var = np.var(y, axis=0)\n", "\n", "    fvaf = 1 - mse/var \n", "    \n", "    rmse = np.sqrt(mse) \n", "    \n", "    if convert_deg:\n", "        rmse = rmse * 180 / np.pi \n", "\n", "    results = {\n", "        'mse'  : np.reshape(mse,  (1, -1)), \n", "        'rmse' : np.reshape(rmse, (1, -1)), \n", "        'fvaf' : np.reshape(fvaf, (1, -1)),  # Fraction of Variance Accounted For\n", "    }\n", "    \n", "    return results\n", "\n"]}, {"cell_type": "markdown", "metadata": {"id": "YS0S51F7d6ru", "wm": "ApccFt0MQeI72fjy", "editable": false}, "source": ["# &#x43;&#x52;&#x4f;&#x53;&#x53;-&#x56;&#x41;&#x4c;&#x49;&#x44;&#x41;&#x54;&#x49;&#x4f;&#x4e;\n", "\n", "&#x54;&#x4f;&#x44;&#x4f;: &#x43;&#x6f;&#x6d;&#x70;&#x6c;&#x65;&#x74;&#x65; &#x74;&#x68;&#x65; &#x69;&#x6d;&#x70;&#x6c;&#x65;&#x6d;&#x65;&#x6e;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x6f;&#x66; &#x74;&#x68;&#x65; &#x4b;&#x46;&#x6f;&#x6c;&#x64;&#x48;&#x6f;&#x6c;&#x69;&#x73;&#x74;&#x69;&#x63;&#x43;&#x72;&#x6f;&#x73;&#x73;&#x56;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x63;&#x6c;&#x61;&#x73;&#x73;.  \n", "* &#x46;&#x6f;&#x72; &#x61; &#x67;&#x69;&#x76;&#x65;&#x6e; &#x6d;&#x6f;&#x64;&#x65;&#x6c; &#x61;&#x6e;&#x64; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x69;&#x6e;&#x67; &#x73;&#x65;&#x74; &#x73;&#x69;&#x7a;&#x65;, &#x74;&#x68;&#x69;&#x73; &#x63;&#x6c;&#x61;&#x73;&#x73; &#x77;&#x69;&#x6c;&#x6c; &#x70;&#x65;&#x72;&#x66;&#x6f;&#x72;&#x6d; &#x61; &#x6c;&#x6f;&#x6f;&#x70; &#x6f;&#x76;&#x65;&#x72; &#x72;&#x6f;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e;&#x73;\n", "* &#x46;&#x6f;&#x72; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x62;&#x69;&#x6e;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x6f;&#x66; &#x68;&#x79;&#x70;&#x65;&#x72;-&#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72;&#x73;, &#x74;&#x68;&#x65; &#x6d;&#x6f;&#x64;&#x65;&#x6c; &#x77;&#x69;&#x6c;&#x6c; &#x62;&#x65; &#x69;&#x6e;&#x64;&#x65;&#x70;&#x65;&#x6e;&#x64;&#x65;&#x6e;&#x74;&#x6c;&#x79; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x65;&#x64; &#x61;&#x6e;&#x64; &#x65;&#x76;&#x61;&#x6c;&#x75;&#x61;&#x74;&#x65;&#x64; &#x6f;&#x6e; \n", "&#x74;&#x68;&#x65; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x69;&#x6e;&#x67;, &#x76;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x61;&#x6e;&#x64; &#x74;&#x65;&#x73;&#x74;&#x69;&#x6e;&#x67; &#x73;&#x65;&#x74;&#x73;.  &#x45;&#x76;&#x61;&#x6c;&#x75;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x66;&#x6f;&#x72; &#x65;&#x61;&#x63;&#x68; &#x6d;&#x6f;&#x64;&#x65;&#x6c; &#x77;&#x69;&#x6c;&#x6c; &#x62;&#x65; &#x64;&#x6f;&#x6e;&#x65; &#x62;&#x79; &#x61;\n", "&#x73;&#x70;&#x65;&#x63;&#x69;&#x66;&#x69;&#x65;&#x64; &#x65;&#x76;&#x61;&#x6c;&#x75;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x66;&#x75;&#x6e;&#x63;&#x74;&#x69;&#x6f;&#x6e; (&#x65;&#x76;&#x61;&#x6c;_&#x66;&#x75;&#x6e;&#x63;), &#x77;&#x68;&#x69;&#x63;&#x68; &#x72;&#x65;&#x74;&#x75;&#x72;&#x6e;&#x73; &#x61; &#x64;&#x69;&#x63;&#x74;&#x69;&#x6f;&#x6e;&#x61;&#x72;&#x79; &#x6f;&#x66; &#x6d;&#x65;&#x74;&#x72;&#x69;&#x63; &#x76;&#x61;&#x6c;&#x75;&#x65;&#x73;.\n", "&#x54;&#x68;&#x65;&#x73;&#x65; &#x72;&#x65;&#x73;&#x75;&#x6c;&#x74;&#x73; &#x61;&#x72;&#x65; &#x63;&#x6f;&#x6c;&#x6c;&#x61;&#x74;&#x65;&#x64; &#x61;&#x63;&#x72;&#x6f;&#x73;&#x73; &#x74;&#x68;&#x65; &#x72;&#x6f;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e;&#x73;.  &#x54;&#x68;&#x65; &#x72;&#x65;&#x74;&#x75;&#x72;&#x6e; &#x73;&#x74;&#x72;&#x75;&#x63;&#x74;&#x75;&#x72;&#x65;&#x73; &#x69;&#x6e;&#x63;&#x6c;&#x75;&#x64;&#x65; &#x74;&#x68;&#x65; \n", "&#x70;&#x65;&#x72;&#x66;&#x6f;&#x72;&#x6d;&#x61;&#x6e;&#x63;&#x65; &#x66;&#x6f;&#x72; &#x65;&#x61;&#x63;&#x68; &#x72;&#x6f;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e;, &#x61;&#x73; &#x77;&#x65;&#x6c;&#x6c; &#x61;&#x73; &#x74;&#x68;&#x65; &#x6d;&#x65;&#x61;&#x6e; &#x61;&#x6e;&#x64; &#x73;&#x74;&#x61;&#x6e;&#x64;&#x61;&#x72;&#x64; &#x64;&#x65;&#x76;&#x69;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x61;&#x63;&#x72;&#x6f;&#x73;&#x73; &#x74;&#x68;&#x65; &#x72;&#x6f;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e;&#x73;.\n", "\n", "\n<font style=\"font-size:0px\">&#x55;&#x73;&#x65; &#x61; &#x6c;&#x6f;&#x74; &#x6f;&#x66; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x61;&#x6e;&#x64; &#x70;&#x72;&#x65;&#x66;&#x61;&#x63;&#x65; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74; &#x77;&#x69;&#x74;&#x68; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x70;&#x6f;&#x75;&#x6e;&#x64; &#x73;&#x69;&#x67;&#x6e;\n", "\n", "&#x54;&#x68;&#x65; &#x66;&#x6f;&#x6c;&#x6c;&#x6f;&#x77;&#x69;&#x6e;&#x67; &#x63;&#x65;&#x6c;&#x6c;&#x73; &#x69;&#x6e;&#x63;&#x6c;&#x75;&#x64;&#x65; &#x69;&#x6e;&#x73;&#x74;&#x72;&#x75;&#x63;&#x74;&#x69;&#x6f;&#x6e;&#x73; &#x66;&#x6f;&#x72; &#x77;&#x68;&#x61;&#x74; &#x74;&#x68;&#x65; &#x6b;&#x65;&#x79; &#x6d;&#x65;&#x74;&#x68;&#x6f;&#x64;&#x73; &#x73;&#x68;&#x6f;&#x75;&#x6c;&#x64; &#x64;&#x6f;."]}, {"cell_type": "markdown", "metadata": {"id": "YS0S51F7d6ru", "wm": "ApccFt0MQeI72fjy"}, "source": ["## Method: init(self, model, eval_func, rotation_skip=1)\n", "\n", "```\n", ":param model: The Scikit-Learn model to be trained\n", ":param eval_func: Python function that will be used to evaluate a model\n", "        parameters of the function: (inputs, desired outputs, model predictions)\n", ":param rotation_skip: Number of CV rotations for every one rotation that is actually trained and evaluated.  \n", "        Typical use is 1 (train and evaluate all rotations), but when we are \n", "        debugging, it is helpful to perform a smaller number of train/evaluate\n", "        cycles (e.g., 4, 5, or 10 assuming 20 folds).\n", "```"]}, {"cell_type": "markdown", "metadata": {"id": "YS0S51F7d6ru", "wm": "ApccFt0MQeI72fjy"}, "source": ["## Method: perform_cross_validation(self, X, y, folds_idx, trainsize):\n", "\n", "TODO: This is where the bulk of the work will be done\n", "Perform cross-validation for a singular train set size and single \n", "hyper-parameter set, by evaluating the model's performance over \n", "multiple data set rotations.\n", "\n", "NOTE: This function assumes that the hyper-parameters have already been set in the model\n", "```\n", ":param X: numpy array containing all of the input data (folds concatenated together)\n", ":param y: numpy array containing all of the desired output data \n", "       (folds concatenated together)\n", ":param folds_idx: list of lists containing the indexes of each element in each fold, e.g.,\n", "        folds_idx[i] = [start_idx, ... , end_idx]\n", ":param trainsize: number of folds to use for training\n", "```\n", "\n", "RETURNS: train, val, and test set results for all rotations of the data sets and the summary  of the results (i.e., the mean/standard devation over all the rotations). \n", "         \n", "results is a dictionary of dictionaries of r-by-n numpy  arrays, where r is the number of r\n", "otations (divided by skip), and n is the number of outputs from the model.\n", "         \n", "summary is a dict of dictionaries of 1-by-n numpy arrays containing the mean and standard deviation of the metrics in results across all rotations\n", "         \n", "In our BMI dataset, n = 2 (e.g., shoulder torque and elbow)\n", "\n", "Data structure details:\n", "```\n", "results.keys() = ['train', 'val', 'test']\n", "results['train'].keys() = ['metric1', 'metric2', ...]\n", "   where metrics are defined by the dictionary returned by the eval_func\n", "results['train']['metric1'] = numpy_array\n", "\n", "results = \n", " {\n", "    'train':\n", "             {\n", "                 'mse' : r_by_n_numpy_array,\n", "                 'rmse': r_by_n_numpy_array, \n", "                 ...\n", "             },\n", "    'val'  : {...},\n", "    'test' : {...}\n", " }\n", " \n", " summary = \n", " {\n", "    'train':\n", "             {\n", "                 'mse_mean' : 1_by_n_numpy_array,\n", "                 'mse_std'  : 1_by_n_numpy_array,\n", "                 'rmse_mean': 1_by_n_numpy_array, \n", "                 'rmse_std' : 1_by_n_numpy_array,\n", "                 ...\n", "             },\n", "    'val'  : {...},\n", "    'test' : {...}\n", " }\n", "```\n", "\n", "For example, you can access the MSE results for the validation set like so:\n", "```\n", "    results['val']['mse']\n", "```\n", "\n", "You can access the summary (i.e. the average results over all the rotations) for the test set for the rMSE like so:\n", "```\n", "    summary['test']['rmse_mean']\n", "```\n", "\n", "TODO: complete the implementation so that it performs the full set rotations for \n", "a given model."]}, {"cell_type": "markdown", "metadata": {"id": "YS0S51F7d6ru", "wm": "ApccFt0MQeI72fjy"}, "source": ["## Method: get_data(self, X, y, folds_idx, nfolds, rotation, trainsize):\n", " \n", "Given all of the available data, and the data rotation, create training,\n", "validation and testing data sets.\n", "\n", "```\n", ":param X: Unified numpy array of all model inputs\n", ":param y: Unified numpy array of all model desired outputs\n", ":param fold_idx: List of lists.  Each sub-list contains the indices in the unifed array\n", "  for the samples that correspond to the corresponding fold.\n", ":param nfolds: Total number of folds\n", ":param rotation: Data set rotation\n", ":param trainsize: Number of folds to use for training\n", "\n", ":return:\n", "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n", "    (inputs and desired outputs for training, validation and testing sets)\n", "```\n", "\n", "TODO: complete the implementation so that it returns the three data sets.\n"]}, {"cell_type": "markdown", "metadata": {"id": "BzmIoQXcd6rw", "wm": "ApccFt0MQeI72fjy", "editable": false}, "source": ["\n", "# &#x63;&#x6c;&#x61;&#x73;&#x73; &#x43;&#x72;&#x6f;&#x73;&#x73;&#x56;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e;&#x47;&#x72;&#x69;&#x64;&#x53;&#x65;&#x61;&#x72;&#x63;&#x68;\n", "\n", "&#x54;&#x68;&#x69;&#x73; &#x63;&#x6c;&#x61;&#x73;&#x73; &#x69;&#x73; &#x72;&#x65;&#x73;&#x70;&#x6f;&#x6e;&#x73;&#x69;&#x62;&#x6c;&#x65; &#x66;&#x6f;&#x72; &#x70;&#x65;&#x72;&#x66;&#x6f;&#x72;&#x6d;&#x69;&#x6e;&#x67; &#x63;&#x72;&#x6f;&#x73;&#x73;-&#x76;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x65;&#x78;&#x70;&#x65;&#x72;&#x69;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x66;&#x6f;&#x72; &#x65;&#x61;&#x63;&#x68;\n", "&#x63;&#x6f;&#x6d;&#x62;&#x69;&#x6e;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x6f;&#x66; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x69;&#x6e;&#x67; &#x73;&#x65;&#x74; &#x73;&#x69;&#x7a;&#x65; &#x61;&#x6e;&#x64; &#x68;&#x79;&#x70;&#x65;&#x72;&#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72; &#x73;&#x65;&#x74;.   &#x49;&#x6e; &#x61;&#x64;&#x64;&#x69;&#x74;&#x69;&#x6f;&#x6e;, &#x74;&#x68;&#x69;&#x73; \n", "&#x63;&#x6c;&#x61;&#x73;&#x73; &#x70;&#x72;&#x6f;&#x76;&#x69;&#x64;&#x65;&#x73; &#x61; &#x72;&#x61;&#x6e;&#x67;&#x65; &#x6f;&#x66; &#x74;&#x6f;&#x6f;&#x6c;&#x73; &#x66;&#x6f;&#x72; &#x65;&#x78;&#x74;&#x72;&#x61;&#x63;&#x74;&#x69;&#x6e;&#x67; &#x61;&#x6e;&#x64; &#x76;&#x69;&#x73;&#x75;&#x61;&#x6c;&#x69;&#x7a;&#x69;&#x6e;&#x67; &#x74;&#x68;&#x65; &#x72;&#x65;&#x73;&#x75;&#x6c;&#x74;&#x73; &#x6f;&#x66; \n", "&#x74;&#x68;&#x65;&#x73;&#x65; &#x65;&#x78;&#x70;&#x65;&#x72;&#x69;&#x6d;&#x65;&#x6e;&#x74;&#x73;.\n", "\n", "&#x42;&#x65;&#x63;&#x61;&#x75;&#x73;&#x65; &#x74;&#x68;&#x69;&#x73; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x6c;&#x6f;&#x6f;&#x70; &#x69;&#x73; &#x63;&#x6f;&#x6d;&#x70;&#x75;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e;&#x61;&#x6c;&#x6c;&#x79; &#x69;&#x6e;&#x76;&#x6f;&#x6c;&#x76;&#x65;&#x64;, &#x77;&#x65; &#x77;&#x69;&#x6c;&#x6c; &#x63;&#x68;&#x65;&#x63;&#x6b;&#x70;&#x6f;&#x69;&#x6e;&#x74; &#x74;&#x68;&#x65; \n", "&#x72;&#x65;&#x73;&#x75;&#x6c;&#x74;&#x73; &#x6f;&#x66; &#x65;&#x61;&#x63;&#x68; &#x72;&#x75;&#x6e; &#x74;&#x6f; &#x61; &#x70;&#x69;&#x63;&#x6b;&#x6c;&#x65; &#x66;&#x69;&#x6c;&#x65;.  &#x54;&#x68;&#x69;&#x73; &#x77;&#x61;&#x79;, &#x69;&#x66; &#x74;&#x68;&#x65; &#x6c;&#x6f;&#x6f;&#x70; &#x69;&#x73; &#x69;&#x6e;&#x74;&#x65;&#x72;&#x72;&#x75;&#x70;&#x74;&#x65;&#x64;,\n", "&#x69;&#x74; &#x77;&#x69;&#x6c;&#x6c; &#x72;&#x65;&#x73;&#x74;&#x61;&#x72;&#x74; &#x74;&#x68;&#x65; &#x72;&#x75;&#x6e; &#x77;&#x68;&#x65;&#x72;&#x65; &#x69;&#x74; &#x6c;&#x65;&#x66;&#x74; &#x6f;&#x66;&#x66;.\n", "\n", "\n<font style=\"font-size:0px\">&#x55;&#x73;&#x65; &#x61; &#x6c;&#x6f;&#x74; &#x6f;&#x66; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x61;&#x6e;&#x64; &#x70;&#x72;&#x65;&#x66;&#x61;&#x63;&#x65; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74; &#x77;&#x69;&#x74;&#x68; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x70;&#x6f;&#x75;&#x6e;&#x64; &#x73;&#x69;&#x67;&#x6e;\n", "\n", "&#x54;&#x68;&#x65; &#x63;&#x65;&#x6c;&#x6c;&#x73; &#x62;&#x65;&#x6c;&#x6f;&#x77; &#x64;&#x65;&#x73;&#x63;&#x72;&#x69;&#x62;&#x65; &#x74;&#x68;&#x65; &#x6b;&#x65;&#x79; &#x6d;&#x65;&#x74;&#x68;&#x6f;&#x64;&#x73;."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "mBwCLg43d6rv", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["'''\n", "TODO: Complete K-Fold Cross-Validation implementation\n", "\n", "'''\n", "class KFoldHolisticCrossValidation():\n", "    '''\n", "    Cross-validation class. This class will perform cross-validation across for a \n", "    single hyper-parameter set.\n", "    '''\n", "    def __init__(self, model, eval_func, rotation_skip=1):\n", "        '''\n", "        :param model: The Scikit-Learn model to be trained\n", "        :param eval_func': Python function that will be used to evaluate a model\n", "                                parameters: (inputs, desired outputs, model predictions)\n", "        :param rotation_skip: Number of CV rotations for every one rotation that is actually trained & evaluated.  \n", "                                Typical is 1 (train and evaluate all rotations), but when we are \n", "                                debugging, it is helpful to perform a smaller number of train/evaluate\n", "                                cycles.\n", "        '''\n", "        self.model = model\n", "        self.eval_func = eval_func\n", "        self.rotation_skip = rotation_skip\n", "\n", "    def perform_cross_validation(self, X, y, folds_idx, trainsize):\n", "        ''' TODO      \n", "        \n", "        Documentation is given above\n", "        '''\n", "        \n", "        # Verify that a valid train set size was provided\n", "        nfolds = len(folds_idx)\n", "        if trainsize > nfolds - 2: \n", "            err_msg = \"ERROR: KFoldHolisticCrossValidation.perform_cross_validation() - \"\n", "            err_msg += \"trainsize (%d) cant be more than nfolds (%d) - 2\" % (trainsize, nfolds)\n", "            raise ValueError(err_msg)\n", "        \n", "        # Set up results data structures for each rotation\n", "        results = {'train': None, 'val': None, 'test': None}\n", "        summary = {'train': {}, 'val': {}, 'test': {}}\n", "        \n", "        model = self.model\n", "        evaluate = self.eval_func\n", "        \n", "        # Proceed through the different data rotations\n", "        for rotation in range(0, nfolds, self.rotation_skip):\n", "            (\n", "                Xtrain, ytrain, Xval, yval,  Xtest, ytest\n", "            ) = self.get_data(X, y, folds_idx, nfolds, rotation, trainsize)\n", "\n", "            print('Rotation:', rotation, '; train examples:', ytrain.shape)\n", "            \n", "            # TODO: Train model using the training set\n", "            # TODO\n", "\n", "            # TODO: Evaluate the model for each data set\n", "            # TODO\n", "\n", "            # Record the train, val, and test set results. These are dicts \n", "            # of result metrics, returned by the evaluate function\n", "\n", "            if results['train'] is None: \n", "                # First rotation: initialize structures\n", "                results['train'] = res_train\n", "                results['val'] = res_val\n", "                results['test'] = res_test\n", "            else:\n", "                # Other rotations: add results to existing structures\n", "                for metric in res_train.keys():\n", "                    results['train'][metric] = np.append(results['train'][metric], res_train[metric], axis=0)\n", "                    results['val'][metric] = np.append(results['val'][metric], res_val[metric], axis=0)\n", "                    results['test'][metric] = np.append(results['test'][metric], res_test[metric], axis=0)\n", "\n", "        # Compute/record mean and standard deviation for the size for each metric\n", "        #  The mean is across the rotations\n", "        for metric in results['train'].keys():\n", "            for stat_set in ['train', 'val', 'test']:\n", "                summary[stat_set][metric+'_mean'] = np.mean(results[stat_set][metric], \n", "                                                            axis=0).reshape(1, -1)\n", "                summary[stat_set][metric+'_std'] = np.std(results[stat_set][metric], \n", "                                                          axis=0).reshape(1, -1)\n", "\n", "        return results, summary\n", "\n", "    def get_data(self, X, y, folds_idx, nfolds, rotation, trainsize):\n", "        '''TODO\n", "        \n", "        '''\n", "        # Determine folds to use \n", "        # (eg fold 1,2,3 for trainsize=3, rotation=1, nfolds=20)\n", "        trainfolds = (np.arange(trainsize) + rotation) % nfolds\n", "        # Single fold for validation\n", "        valfold = (nfolds - 2 + rotation) % nfolds\n", "        # Single fold for testing\n", "        testfold = (valfold + 1) % nfolds\n", "        \n", "        # Construct a list to serve as an index into X for our training\n", "        # samples. This will contain the index of each sample the training set\n", "        train_idx = []\n", "        for i in trainfolds:\n", "            # the + operator concatenates raw python lists\n", "            train_idx += folds_idx[i] \n", "\n", "        # TODO: Construct train set by indexing into X and y with the indices of the\n", "        #  samples that belong to the training set\n", "        Xtrain = X[train_idx]\n", "        ytrain = y[train_idx]\n", "        \n", "        # TODO: Construct validation set using the valfold (a single fold!)\n", "        #       Hint: this is always one fold\n", "        Xval = #TODO\n", "        yval = #TODO\n", "\n", "        # TODO: Construct test set using the testfold (a single fold!)\n", "        Xtest = #TODO\n", "        ytest = #TODO\n", "        \n", "        return Xtrain, ytrain, Xval, yval, Xtest, ytest\n"]}, {"cell_type": "markdown", "metadata": {"id": "BzmIoQXcd6rw", "wm": "ApccFt0MQeI72fjy"}, "source": ["## Method: cross_validation_gridsearch(self, X, y, folds_idx, checkpoint_fname=None):\n", "\n", "Perform the grid search with the given data (X, y, folds_idx).  Specifically, this grid search will attempt all possible hyper-parameter values and all possible training set sizes.\n", "\n", "```\n", ":param X: Unified input data\n", ":param y: Unified desired output data\n", ":param folds_idx: List of lists of row indices, one for each fold\n", ":param checkpoint_fname: Name of the output checkpoint file.  If None, then not written to file.\n", "```\n", "\n", "This grid search is smart in that if a specific set of hyper-parameters have already been tested, then building and evaluating for those hyper-parameters will not be done again.  This way, if your experiment is interrupted, you will not have to start from scratch.\n", "\n", "Ther are two levels of caching: as a full set of results are generated for one hyper-parameter set, these are added to the full cache.  Each of these results are componsed of smaller results (one for each training set size).  The secondary cache accumulates these smaller results until all training set sizes are completed."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "BzmIoQXcd6rw", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["class CrossValidationGridSearch():\n", "    '''\n", "    This class is responsible for performing a grid trainsizes x paramsets CV experiments.\n", "    For each grid point, N-fold crossvalidation is performed (with potential skips in the\n", "    possible rotations).\n", "    \n", "    '''\n", "    def __init__(self, model, paramsets, eval_func, opt_metric, \n", "                 maximize_opt_metric=False, trainsizes=[1], rotation_skip=1,\n", "                 submodel_name=None\n", "                ):\n", "        ''' TODO\n", "        Class instance constructor\n", "        \n", "        :param model: Model to be trained\n", "        :param paramsets: List of dicts.  Every dict contains a set of hyper-parameters for use in\n", "                            one experiment\n", "        :param eval_func: Python function that will be used to evaluate a model\n", "                                parameters: (inputs, desired outputs, model predictions)\n", "        :param opt_metric: Optimization metric to be used.  Must be included in the \n", "                          list of metrics returned by eval_func\n", "        :param maximize_opt_metric: True -> best model has high value for performance metric; \n", "                                    False -> best model has low value\n", "        :param trainsizes: A list of training set sizes (in terms of number of folds)\n", "        :param rotation_skip: Number of CV rotations for every one rotation to train & evaluate.  \n", "                                Typical is 1 (train and evaluate all rotations), but when we are \n", "                                debugging, it is helpful to perform a smaller number of train/evaluate\n", "                                cycles\n", "        :param submodel_name: If the model is a pipeline, then this is the name of the pipeline\n", "                                component that will make use of the hyper-parameters\n", "        '''\n", "        self.model = model\n", "        self.paramsets = paramsets \n", "        self.trainsizes = trainsizes \n", "        self.eval_func = eval_func\n", "        self.opt_metric = opt_metric + '_mean' \n", "        self.maximize_opt_metric = maximize_opt_metric \n", "        self.rotation_skip = rotation_skip \n", "        self.submodel_name = submodel_name\n", "        \n", "        # Results attributes\n", "        # Full recording of all results for all paramsets, sizes, rotations,\n", "        # and metrics. This is a list of dictionaries for each paramset\n", "        self.results = []\n", "        self.results_partial = {}\n", "        # Validation summary report of all means and standard deviations for \n", "        # all metrics, for all paramsets, and sizes. This is a 3D s x r x p \n", "        # numpy array. Where s is the number of training set sizes, r the number of summary \n", "        # metrics +2, and p is the number of hyper-parameter sets\n", "        self.report_by_size = None\n", "        # List of the indices of the best paramset for each size\n", "        self.best_param_inds = None\n", "        self.id = random.randint(0,10000001)\n", "\n", "    def load_checkpoint(self, fname):\n", "        ''' PROVIDED\n", "        Load a checkpoint file into self.results\n", "        \n", "        :param fname: Full name of the file to load the checkpoint from. \n", "        '''\n", "        if not os.path.exists(fname):\n", "            raise ValueError('File %s does not exist'%fname)\n", "        \n", "        with open(fname, 'rb') as f:\n", "            self.results = pkl.load(f)\n", "            self.results_partial = pkl.load(f)\n", "            self.id = pkl.load(f)\n", "            \n", "    def dump_checkpoint(self, fname):\n", "        ''' PROVIDED\n", "        Write the current set of results to a checkpoint file\n", "        \n", "        :param fname: Full name of file to write checkpoint to\n", "        '''\n", "        with open(fname, 'wb') as f:\n", "            pkl.dump(self.results, f)\n", "            pkl.dump(self.results_partial, f)\n", "            pkl.dump(self.id, f)\n", "            \n", "    def reset_results(self):\n", "        ''' PROVIDED\n", "        Reset the current set of results that are stored internally\n", "        '''\n", "        self.results = []\n", "        self.results_partial = {}\n", "    \n", "    def cross_validation_gridsearch(self, X, y, folds_idx, checkpoint_fname=None):\n", "        ''' TODO\n", "\n", "            Documentation given above.\n", "        '''\n", "\n", "        # Create the cross-validation instance\n", "        cross_val = KFoldHolisticCrossValidation(\n", "            self.model, self.eval_func, \n", "            rotation_skip = self.rotation_skip\n", "        )        \n", "        \n", "        # Try to load the checkpoint file\n", "        if checkpoint_fname is not None and os.path.exists(checkpoint_fname):\n", "            self.load_checkpoint(checkpoint_fname)\n", "\n", "        # Iterate over the parameter sets\n", "        for params in self.paramsets:\n", "\n", "            # Check that we haven't already done this before (from our checkpoint)\n", "            if params in [r['params'] for r in self.results]:\n", "                # Don't execute for this set of parameters\n", "                print('already evaled:', params)\n", "                continue\n", "      \n", "            print('evaling on:', params)\n", "        \n", "            # Set up the results for these parametrs\n", "            param_results = []\n", "            param_summary = None\n", "\n", "            # Set the parameters in the model\n", "            if self.submodel_name is not None:\n", "                self.model[self.submodel_name].set_params(**params)\n", "            else:\n", "                self.model.set_params(**params)\n", "            \n", "            # Iterate over the different train set sizes\n", "            # Running cross-validation on them\n", "            for size in self.trainsizes:\n", "                if size in self.results_partial.keys():\n", "                    # We had cached this already\n", "                    print('%d cached'%(size))\n", "                    \n", "                    result = self.results_partial[size]['result'], \n", "                    summary = self.results_partial[size]['summary']\n", "                else:\n", "                    # Haven't done this case yet\n", "                    print('Executing size %d'%(size))\n", "                    \n", "                    # TODO: Perform Cross-Validation using cross_val\n", "                    # TODO\n", "                    \n", "                    # Push this out to the seconary cache\n", "                    self.results_partial[size] = {'result': result, 'summary': summary}\n", "                    \n", "                    if checkpoint_fname is not None:\n", "                        self.dump_checkpoint(checkpoint_fname)\n", "                    \n", "                # Append results in param_results\n", "                param_results.append(result)\n", "                \n", "                # Append the mean and standard deviation statistics (summary)\n", "                if param_summary is None: \n", "                    param_summary = summary\n", "                else:\n", "                    # For each metric measured, append the summary results\n", "                    for metric in summary['train'].keys():\n", "                        for stat_set in ['train', 'val', 'test']:\n", "                            param_summary[stat_set][metric] = np.append(\n", "                                param_summary[stat_set][metric], \n", "                                summary[stat_set][metric], \n", "                                axis=0\n", "                            )\n", "                            \n", "            # Add this param set results to the primary cache\n", "            self.results.append({\n", "                'params' :params,\n", "                'results':param_results, \n", "                'summary':param_summary\n", "            })\n", "            \n", "            # Clear the secondary cache\n", "            self.results_partial = {}\n", "\n", "            # Write the checkpoint file\n", "            if checkpoint_fname is not None:\n", "                self.dump_checkpoint(checkpoint_fname)\n", "        \n", "\n", "    def get_reports_all(self):\n", "        ''' PROVIDED\n", "        Generate reports on the internally stored results\n", "        \n", "        :return: Dictionary containing two keys: 'report_by_size', 'best_param_inds'\n", "        '''\n", "        self.report_by_size = self.get_reports()\n", "        self.best_param_inds = self.get_best_params(\n", "            self.opt_metric, self.maximize_opt_metric\n", "        )\n", "        print(\"CS:\", self.id)\n", "        \n", "        return {\n", "            'report_by_size' : self.report_by_size, \n", "            'best_param_inds': self.best_param_inds\n", "        }\n", "    \n", "    # Report generation code. Provided, but you should still read it\n", "    \"\"\" PROVIDED\n", "    Functions to generate a report of the result of the cross-validation r5un\n", "    \"\"\"\n", "    def get_reports(self):\n", "        ''' PROVIDED\n", "        Get the mean validation summary of all the parameters for each size\n", "        for all metrics. This is used to determine the best parameter set  \n", "        for each size\n", "        \n", "        RETURNS: the report_by_size as a 3D s x r x p array. Where s is \n", "                 the number of train sizes tried, r is the number of summary  \n", "                 metrics evaluated+2, and p is the number of parameter sets.\n", "        '''\n", "        results = self.results\n", "        sizes = np.reshape(self.trainsizes, (1, -1))\n", "        \n", "        nsizes = sizes.shape[1]\n", "        nparams = len(results)\n", "        \n", "        # Set up the reports objects\n", "        metrics = list(results[0]['summary']['val'].keys())\n", "        colnames = ['params', 'size'] + metrics \n", "        report_by_size = np.empty((nsizes, len(colnames), nparams), dtype=object)\n", "\n", "        # Determine mean val for each paramset for each size for all metrics\n", "        for p, paramset_result in enumerate(results):\n", "            params = paramset_result['params']\n", "            res_val = paramset_result['summary']['val']\n", "\n", "            # Compute mean val result for each train size for each metric\n", "            means_by_size = [np.mean(res_val[metric], axis=1) \n", "                             for metric in metrics]\n", "            \n", "            # Include the train set sizes into the report\n", "            means_by_size = np.append(sizes, means_by_size, axis=0)\n", "            \n", "            # Include the parameter sets into the report\n", "            param_strgs = np.reshape([str(params)]*nsizes, (1, -1))\n", "            means_by_size = np.append(param_strgs, means_by_size, axis=0).T\n", "            \n", "            # Append the parameter set means into the report \n", "            report_by_size[:,:,p] = means_by_size\n", "        return report_by_size\n", "\n", "    def get_best_params(self, opt_metric, maximize_opt_metric):\n", "        ''' PROVIDED \n", "        Determines the best parameter set for each train size,  \n", "        based on a specific metric.\n", "        \n", "        PARAMS:\n", "            opt_metric: optimized metric. one of the metrics returned \n", "                        from eval_func, with '_mean' appended for the\n", "                        summary stat. This is the mean metric used to  \n", "                        determine the best parameter set for each \n", "                        training set size\n", "                        \n", "            maximize_opt_metric: True if the max of opt_metric should be\n", "                                 used to determine the best parameters.\n", "                                 False if the min should be used.\n", "                                 \n", "        RETURNS: list of best parameter set indicies for each training set size \n", "        '''\n", "        results = self.results\n", "        report_by_size = self.report_by_size \n", "                \n", "        metrics = list(results[0]['summary']['val'].keys())\n", "        \n", "        # Determine best params for each size, for the optimized metric\n", "        best_param_inds = None\n", "        metric_idx = metrics.index(opt_metric)\n", "        \n", "        # Report info for all paramsets for the optimized metric\n", "        report_opt_metric = report_by_size[:, metric_idx+2, :]\n", "        \n", "        if maximize_opt_metric:\n", "            # Add two for the additional cols for params and size\n", "            best_param_inds = np.argmax(report_opt_metric, axis=1)\n", "        else: \n", "            best_param_inds = np.argmin(report_opt_metric, axis=1)\n", "            \n", "        # Return list of best params indices for each size\n", "        return best_param_inds\n", "    \n", "    def get_best_params_strings(self):\n", "        ''' PROVIDED\n", "        Generates a list of strings of the best params for each size\n", "        RETURNS: list of strings of the best params for each size\n", "        '''\n", "        \n", "        best_param_inds = self.best_param_inds\n", "        results = self.results\n", "        \n", "        return [str(results[p]['params']) for p in best_param_inds]\n", "\n", "    def get_report_best_params_for_size(self, size):\n", "        ''' PROVIDED\n", "        Get the mean validation summary for the best parameter set \n", "        for a specific size for all metrics.\n", "        PARAMS:\n", "            size: index of desired train set size for the best  \n", "                  paramset to come from. Size here is the index in \n", "                  the trainsizes list, NOT the actual number of folds.\n", "                  \n", "        RETURNS: the best parameter report for the size as an s x m  \n", "                 dataframe. Where each row is for a different size, and \n", "                 each column is for a different summary metric.\n", "        '''\n", "        best_param_inds = self.best_param_inds\n", "        report_by_size = self.report_by_size \n", "        \n", "        bp_index = best_param_inds[size]\n", "        size_len = len(size) if type(size) is list else 1\n", "                \n", "        metrics = list(self.results[0]['summary']['val'].keys())\n", "        colnames = ['params', 'size'] + metrics\n", "        report_best_params_for_size = pd.DataFrame(\n", "            report_by_size[size_idx].T[bp_index].reshape(size_len,-1),\n", "            columns=colnames\n", "        )\n", "        return report_best_params_for_size\n", "\n", "    #############################################################\n", "    \"\"\" PROVIDED\n", "    Plotting code to display the result of the grid search and cross-validation\n", "    \"\"\"\n", "\n", "    def plot_cv(self, foldsindices, results, summary, metrics, size):\n", "        ''' PROVIDED\n", "        Plotting function for after perform_cross_validation(), \n", "        displaying the train and val set performances for each rotation \n", "        of the training set. \n", "        \n", "        PARAMS:\n", "            foldsindices: indices of the train sets tried\n", "            results: results from perform_cross_validation()\n", "            summary: mean and standard deviations of the results\n", "            metrics: list of result metrics to plot. Available metrics \n", "                     are the keys in the dict returned by eval_func\n", "            size: train set size\n", "            \n", "        RETURNS: the figure and axes handles\n", "        '''\n", "        nmetrics = len(metrics)\n", "\n", "        # Initialize figure plots\n", "        fig, axs = plt.subplots(nmetrics, 1, figsize=(12,6))\n", "        fig.subplots_adjust(hspace=.4)\n", "        \n", "        # When 1 metric is provided, allow the axs to be iterable\n", "        axs = np.array(axs).ravel()\n", "\n", "        # Construct each subplot\n", "        for metric, ax in zip(metrics, axs):\n", "            # Compute the mean for multiple outputs\n", "            res_train = np.mean(results['train'][metric], axis=1)\n", "            res_val = np.mean(results['val'][metric], axis=1)\n", "            \n", "            # Plot\n", "            ax.plot(foldsindices, res_train, label='train')\n", "            ax.plot(foldsindices, res_val, label='val')\n", "            #ax.plot(foldsindices, res_test, label='test')\n", "            ax.set(ylabel=metric)\n", "        axs[0].legend(loc='upper right')\n", "        axs[0].set(xlabel='Fold Index')\n", "        axs[0].set(title='Performance for Train Set Size ' + str(size))\n", "        return fig, axs\n", "\n", "    def plot_param_train_val(self, metrics, paramidx=0, view_test=False):\n", "        ''' PROVIDED\n", "        Plotting function for after grid_cross_validation(), \n", "        displaying the mean (summary) train and val set performances \n", "        for each train set size.\n", "        \n", "        PARAMS:\n", "            metrics: list of summary metrics to plot. '_mean' or '_std'\n", "                     must be appended to the end of the base metric name. \n", "                     These base metric names are the keys in the dict \n", "                     returned by eval_func\n", "            paramidx: parameter set index\n", "            view_test: flag to view the test set results\n", "            \n", "        RETURNS: the figure and axes handles\n", "        '''\n", "        sizes = self.trainsizes\n", "        results = self.results\n", "\n", "        summary = results[paramidx]['summary']\n", "        params = results[paramidx]['params']\n", "        \n", "        nmetrics = len(metrics)\n", "\n", "        # Initialize figure plots\n", "        fig, axs = plt.subplots(nmetrics, 1, figsize=(12,6))\n", "        \n", "        # When 1 metric is provided, allow the axs to be iterable\n", "        axs = np.array(axs).ravel()\n", "\n", "        # Construct each subplot\n", "        for metric, ax in zip(metrics, axs):\n", "            # Compute the mean for multiple outputs\n", "            res_train = np.mean(summary['train'][metric], axis=1)\n", "            res_val = np.mean(summary['val'][metric], axis=1)\n", "            \n", "            # Plot\n", "            ax.plot(sizes, res_train, label='train')\n", "            ax.plot(sizes, res_val, label='val')\n", "            if view_test:\n", "                res_test = np.mean(summary['test'][metric], axis=1)\n", "                ax.plot(sizes, res_test, label='test')\n", "            ax.set(ylabel=metric)\n", "            ax.set_xticks(sizes)\n", "            \n", "        # Final labels\n", "        axs[-1].set(xlabel='Train Set Size (# of folds)')\n", "        axs[0].set(title=str(params))\n", "        axs[0].legend(loc='upper right')\n", "        return fig, axs\n", "    \n", "    def plot_allparams_val(self, metrics):\n", "        ''' PROVIDED\n", "        Plotting function for after grid_cross_validation(), displaying  \n", "        mean (summary) validation set performances for each train size \n", "        for all parameter sets for the specified metrics.\n", "        \n", "        PARAMS:\n", "            metrics: list of summary metrics to plot. '_mean' or '_std' \n", "                     must be append to the end of the base metric name. \n", "                     These base metric names are the keys in the dict \n", "                     returned by eval_func\n", "                     \n", "        RETURNS: the figure and axes handles\n", "        '''\n", "        sizes = self.trainsizes\n", "        results = self.results\n", "        \n", "        nmetrics = len(metrics)\n", "\n", "        # Initialize figure plots\n", "        fig, axs = plt.subplots(nmetrics, 1, figsize=(10,6))\n", "        #fig.subplots_adjust(hspace=.4)\n", "        # When 1 metric is provided, allow the axs to be iterable\n", "        axs = np.array(axs).ravel()\n", "\n", "        # Construct each subplot: one for each metric\n", "        for metric, ax in zip(metrics, axs):\n", "            \n", "            # Iterate over the hyper-parameter sets\n", "            for p, param_results in enumerate(results):\n", "                summary = param_results['summary']\n", "                params = param_results['params']\n", "                # Compute the mean for multiple outputs\n", "                res_val = np.mean(summary['val'][metric], axis=1)                \n", "                ax.plot(sizes, res_val, label=str(params))\n", "                \n", "            # Labels for this metric\n", "            ax.set(ylabel=metric)\n", "            ax.set_xticks(sizes)\n", "            \n", "        # Final labels\n", "        axs[-1].set(xlabel='Train Set Size (# of folds)')\n", "        axs[0].set(title='Validation Performance')\n", "        axs[0].legend(bbox_to_anchor=(1.02, 1), loc='upper left',\n", "                      ncol=1, borderaxespad=0., prop={'size': 8})\n", "        return fig, axs\n", "\n", "    def plot_best_params_by_size(self):\n", "        ''' PROVIDED\n", "        Plotting function for after grid_cross_validation(), displaying \n", "        mean (summary) train and validation set performances for the best \n", "        parameter set for each train size for the optimized metric.\n", "                     \n", "        RETURNS: the figure and axes handles\n", "        '''\n", "        results = self.results\n", "        metric = self.opt_metric\n", "        best_param_inds = self.best_param_inds\n", "        sizes = np.array(self.trainsizes)\n", "\n", "        # Unique set of best params for the legend\n", "        unique_param_sets = np.unique(best_param_inds)\n", "        lgnd_params = [self.paramsets[p] for p in unique_param_sets]\n", "\n", "        # Data set types to display\n", "        set_names = ['train', 'val', 'test']\n", "        \n", "        # Initialize figure\n", "        fig, axs = plt.subplots(len(set_names), 1, figsize=(10,8))\n", "\n", "        # When more than one metric is provided, allow the axs to be iterable\n", "        axs = np.array(axs).ravel()\n", "        \n", "        # Construct each subplot: iterate over data set types (train and val only)\n", "        for i, (ax, set_name) in enumerate(zip(axs, set_names)):\n", "            \n", "            # Iterate over the unique set of hyperparameters\n", "            for p in unique_param_sets:\n", "                # Obtain indices of sizes this paramset was best for\n", "                param_size_inds = np.where(best_param_inds == p)[0]\n", "                param_sizes = sizes[param_size_inds]\n", "                param_sizes.sort()\n", "                # Compute the mean over multiple outputs for each size\n", "                param_summary = results[p]['summary'][set_name]\n", "                metric_scores = np.mean(param_summary[metric][param_size_inds,:], axis=1)\n", "                # Plot the param results for each size it was the best for\n", "                ax.scatter(param_sizes, metric_scores, s=120, marker=(p+2, 1))\n", "                \n", "            # Ticks for all data set sizes\n", "            ax.set_xticks(sizes)\n", "\n", "            set_name += ' Set Performance'\n", "            ax.set(ylabel=metric, title=set_name)\n", "\n", "        # Final labels\n", "        axs[-1].set(xlabel='Train Set Size (# of folds)')\n", "        axs[0].legend(lgnd_params, bbox_to_anchor=(1.02, 1), loc='upper left',\n", "                      ncol=1, borderaxespad=0., prop={'size': 8})\n", "        \n", "        return fig, axs\n", "\n", "\n", " "]}, {"cell_type": "markdown", "metadata": {"id": "R498w0V0d6ry", "wm": "ApccFt0MQeI72fjy", "editable": false}, "source": ["# &#x43;&#x72;&#x6f;&#x73;&#x73;-&#x56;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x66;&#x6f;&#x72; &#x52;&#x69;&#x64;&#x67;&#x65; &#x52;&#x65;&#x67;&#x72;&#x65;&#x73;&#x73;&#x69;&#x6f;&#x6e;\n", "\n", "&#x47;&#x65;&#x6e;&#x65;&#x72;&#x61;&#x74;&#x65; &#x6c;&#x69;&#x73;&#x74; &#x6f;&#x66; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72;&#x73; &#x74;&#x6f; &#x75;&#x73;&#x65; &#x66;&#x6f;&#x72; &#x63;&#x72;&#x6f;&#x73;&#x73;-&#x76;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e;\n", "&#x75;&#x73;&#x69;&#x6e;&#x67; &#x67;&#x65;&#x6e;&#x65;&#x72;&#x61;&#x74;&#x65;_&#x70;&#x61;&#x72;&#x61;&#x6d;&#x73;&#x65;&#x74;&#x73;()\n", "\n", "&#x43;&#x72;&#x65;&#x61;&#x74;&#x65; &#x61; &#x64;&#x69;&#x63;&#x74;&#x69;&#x6f;&#x6e;&#x61;&#x72;&#x79; &#x74;&#x68;&#x61;&#x74; &#x63;&#x6f;&#x6e;&#x74;&#x61;&#x69;&#x6e;&#x73; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72; &#x6c;&#x69;&#x73;&#x74;&#x73; &#x66;&#x6f;&#x72; &#x74;&#x68;&#x65; &#x66;&#x6f;&#x6c;&#x6c;&#x6f;&#x77;&#x69;&#x6e;&#x67; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72;&#x73;\n", "\n", "&#x61;&#x6c;&#x70;&#x68;&#x61;: &#x46;&#x61;&#x63;&#x74;&#x6f;&#x72;&#x73; &#x6f;&#x66; &#x31;&#x30; &#x66;&#x72;&#x6f;&#x6d; &#x31; &#x74;&#x6f; &#x31;&#x30;&#x30;&#x30;&#x30;&#x30;&#x30;\n", "\n", "&#x6d;&#x61;&#x78;_&#x69;&#x74;&#x65;&#x72;: &#x31;&#x30;&#x30;&#x30;&#x30;\n", "\n", "\n<font style=\"font-size:0px\">&#x55;&#x73;&#x65; &#x61; &#x6c;&#x6f;&#x74; &#x6f;&#x66; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x61;&#x6e;&#x64; &#x70;&#x72;&#x65;&#x66;&#x61;&#x63;&#x65; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74; &#x77;&#x69;&#x74;&#x68; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x70;&#x6f;&#x75;&#x6e;&#x64; &#x73;&#x69;&#x67;&#x6e;\n", "\n", "&#x74;&#x6f;&#x6c;: &#x30;.&#x30;&#x30;&#x31;\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KFPq3LXBd6rz", "outputId": "5d838b88-56cf-47e3-bed1-3f39cbc0fe2c", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" TODO\n", "\n", "\"\"\"\n", "\n", "# For testing purposes, you may want to make the parameter lists smaller\n", "\n", "param_lists = #TODO\n", "\n", "\n", "allparamsets = generate_paramsets(param_lists) \n", "\n", "allparamsets"]}, {"cell_type": "markdown", "metadata": {"id": "vtIulw5_d6r1", "wm": "ApccFt0MQeI72fjy", "editable": false}, "source": [" \n", "## &#x43;&#x72;&#x65;&#x61;&#x74;&#x65; &#x61; &#x67;&#x72;&#x69;&#x64; &#x73;&#x65;&#x61;&#x72;&#x63;&#x68; &#x6f;&#x62;&#x6a;&#x65;&#x63;&#x74; &#x66;&#x6f;&#x72; &#x61; &#x52;&#x69;&#x64;&#x67;&#x65; &#x52;&#x65;&#x67;&#x72;&#x65;&#x73;&#x73;&#x69;&#x6f;&#x6e; &#x6d;&#x6f;&#x64;&#x65;&#x6c; &#x50;&#x69;&#x70;&#x65;&#x6c;&#x69;&#x6e;&#x65;\n", "\n", "- &#x43;&#x72;&#x65;&#x61;&#x74;&#x65; &#x74;&#x68;&#x65; &#x6d;&#x6f;&#x64;&#x65;&#x6c;: &#x69;&#x74; &#x69;&#x73; &#x61; &#x70;&#x69;&#x70;&#x65;&#x6c;&#x69;&#x6e;&#x65; &#x74;&#x68;&#x61;&#x74; &#x69;&#x6e;&#x63;&#x6c;&#x75;&#x64;&#x65;&#x73; &#x61; &#x53;&#x74;&#x61;&#x6e;&#x64;&#x61;&#x72;&#x64;&#x53;&#x63;&#x61;&#x6c;&#x65;&#x72; &#x61;&#x6e;&#x64; &#x61; &#x52;&#x69;&#x64;&#x67;&#x65; &#x6f;&#x62;&#x6a;&#x65;&#x63;&#x74;.  &#x54;&#x68;&#x65; &#x6c;&#x61;&#x74;&#x74;&#x65;&#x72; &#x73;&#x68;&#x6f;&#x75;&#x6c;&#x64; &#x62;&#x65; &#x6e;&#x61;&#x6d;&#x65;&#x64; '&#x72;&#x65;&#x67;&#x72;&#x65;&#x73;&#x73;&#x69;&#x6f;&#x6e;'\n", "- &#x55;&#x73;&#x65; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x69;&#x6e;&#x67; &#x73;&#x65;&#x74; &#x73;&#x69;&#x7a;&#x65;&#x73; &#x31;,&#x32;,&#x33;,&#x34;,&#x35;,&#x37;,&#x31;&#x30;,&#x31;&#x33;,&#x31;&#x36;\n", "- &#x55;&#x73;&#x65; &#x72;&#x6d;&#x73;&#x65; &#x61;&#x73; &#x74;&#x68;&#x65; &#x6f;&#x70;&#x74; &#x6d;&#x65;&#x74;&#x72;&#x69;&#x63;\n", "\n<font style=\"font-size:0px\">&#x55;&#x73;&#x65; &#x61; &#x6c;&#x6f;&#x74; &#x6f;&#x66; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x61;&#x6e;&#x64; &#x70;&#x72;&#x65;&#x66;&#x61;&#x63;&#x65; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74; &#x77;&#x69;&#x74;&#x68; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x70;&#x6f;&#x75;&#x6e;&#x64; &#x73;&#x69;&#x67;&#x6e;\n", "\n", "- &#x50;&#x65;&#x72;&#x66;&#x6f;&#x72;&#x6d; &#x61;&#x6c;&#x6c; &#x72;&#x6f;&#x74;&#x61;&#x74;&#x69;&#x6f;&#x6e;&#x73; (&#x74;&#x68;&#x6f;&#x75;&#x67;&#x68; &#x79;&#x6f;&#x75; &#x6d;&#x69;&#x67;&#x68;&#x74; &#x77;&#x61;&#x6e;&#x74; &#x74;&#x6f; &#x74;&#x65;&#x73;&#x74; &#x77;&#x69;&#x74;&#x68; &#x66;&#x65;&#x77;&#x65;&#x72;)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "vtIulw5_d6r1", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" TODO\n", "\n", "\"\"\"\n", "model =  # TODO\n", "\n", "crossval = CrossValidationGridSearch(# TODO"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "icL9zlq5d6r1", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["''' PROVIDED: EXECUTE CELL\n", "\n", "Checkpoint file: for a given gridsearch, we checkpoint the individual training experiments to\n", "a file.  This way, if the search is interrupted, we can restart the search where it left off.  \n", "Also - we can add more hyper-parameter sets later and restart the search.\n", "\n", "'''\n", "\n", "fullcvfname = \"hw6_crossval_ridge_checkpoint.pkl\"\n"]}, {"cell_type": "markdown", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy", "editable": false}, "source": ["\n", "## &#x46;&#x75;&#x6c;&#x6c; &#x47;&#x72;&#x69;&#x64;&#x73;&#x65;&#x61;&#x72;&#x63;&#x68; &#x52;&#x75;&#x6e;\n", "\n", "&#x54;&#x4f;&#x44;&#x4f;: &#x55;&#x73;&#x65; &#x67;&#x72;&#x69;&#x64;_&#x63;&#x72;&#x6f;&#x73;&#x73;_&#x76;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e;() &#x74;&#x6f; &#x72;&#x75;&#x6e; &#x74;&#x68;&#x65; &#x66;&#x75;&#x6c;&#x6c; &#x63;&#x72;&#x6f;&#x73;&#x73;-&#x76;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e; &#x70;&#x72;&#x6f;&#x63;&#x65;&#x64;&#x75;&#x72;&#x65;\n", "\n", "&#x4e;&#x6f;&#x74;&#x65;&#x73;:\n", "&#x31;. &#x57;&#x68;&#x65;&#x6e; &#x74;&#x65;&#x73;&#x74;&#x69;&#x6e;&#x67;, &#x72;&#x75;&#x6e; &#x74;&#x68;&#x69;&#x73; &#x75;&#x73;&#x69;&#x6e;&#x67; &#x73;&#x6d;&#x61;&#x6c;&#x6c; &#x6c;&#x69;&#x73;&#x74;&#x73; &#x6f;&#x66; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72;&#x73; (&#x65;.&#x67;. &#x6f;&#x66; &#x6c;&#x65;&#x6e;&#x67;&#x74;&#x68; &#x32; &#x6f;&#x72; &#x34;) &#x61;&#x6e;&#x64;/&#x6f;&#x72; &#x73;&#x6d;&#x61;&#x6c;&#x6c; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x73;&#x69;&#x7a;&#x65; &#x6c;&#x69;&#x73;&#x74;&#x73;  (&#x65;.&#x67;. [&#x31;, &#x32;, &#x33;, &#x34;, &#x35;])\n", "&#x32;. &#x46;&#x6f;&#x72; &#x74;&#x68;&#x65; &#x66;&#x69;&#x6e;&#x61;&#x6c; &#x73;&#x75;&#x62;&#x6d;&#x69;&#x73;&#x73;&#x69;&#x6f;&#x6e;, &#x6d;&#x61;&#x6b;&#x65; &#x73;&#x75;&#x72;&#x65; &#x74;&#x6f; &#x75;&#x73;&#x65; &#x74;&#x68;&#x65; &#x63;&#x6f;&#x6d;&#x70;&#x6c;&#x65;&#x74;&#x65; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72; &#x73;&#x65;&#x74; &#x6c;&#x69;&#x73;&#x74; &#x61;&#x6e;&#x64; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x73;&#x69;&#x7a;&#x65; &#x6c;&#x69;&#x73;&#x74; &#x70;&#x72;&#x6f;&#x76;&#x69;&#x64;&#x65;&#x64;/&#x73;&#x70;&#x65;&#x63;&#x69;&#x66;&#x69;&#x65;&#x64;.  &#x54;&#x68;&#x69;&#x73; &#x77;&#x69;&#x6c;&#x6c; &#x74;&#x61;&#x6b;&#x65; &#x73;&#x6f;&#x6d;&#x65; &#x74;&#x69;&#x6d;&#x65; (&#x6c;&#x6f;&#x6e;&#x67;&#x65;&#x72; &#x74;&#x68;&#x61;&#x6e; &#x61;&#x6e; &#x68;&#x6f;&#x75;&#x72;)\n", "&#x33;. &#x57;&#x68;&#x65;&#x6e; &#x72;&#x65;-&#x72;&#x75;&#x6e;&#x6e;&#x69;&#x6e;&#x67; &#x65;&#x76;&#x65;&#x72;&#x79;&#x74;&#x68;&#x69;&#x6e;&#x67;, &#x73;&#x65;&#x74; &#x66;&#x6f;&#x72;&#x63;&#x65; &#x74;&#x6f; &#x54;&#x72;&#x75;&#x65;\n", "\n<font style=\"font-size:0px\">&#x55;&#x73;&#x65; &#x61; &#x6c;&#x6f;&#x74; &#x6f;&#x66; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x61;&#x6e;&#x64; &#x70;&#x72;&#x65;&#x66;&#x61;&#x63;&#x65; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74; &#x77;&#x69;&#x74;&#x68; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x70;&#x6f;&#x75;&#x6e;&#x64; &#x73;&#x69;&#x67;&#x6e;\n", "\n", "&#x34;. &#x50;&#x52;&#x45;&#x44;&#x49;&#x43;&#x54; &#x74;&#x6f;&#x72;&#x71;&#x75;&#x65;"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" TODO\n", "Execute the grid_cross_validation() procedure for all \n", "parameters and sizes\n", "\n", "CLEAN\n", "\"\"\"\n", "# TODO: make sure this is set appropriately. \"True\" if you want to \n", "#       just always to run cross validation, \"False\" if you want \n", "#       to re-load results from the previous cross-validation run\n", "\n", "# If you change the parameters but do not set force = True,\n", "# the model will not be re-run and your previously selected\n", "# parameters will be used\n", "#force = False\n", "force = True\n", "\n", "if force and os.path.exists(fullcvfname):\n", "    # Delete the checkpoint file\n", "    os.remove(fullcvfname)\n", "    \n", "\n", "    \n", "crossval.cross_validation_gridsearch(# TODO\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["# PROVIDED: EXECUTE CELL\n", "# Get the report from the training process\n", "crossval_report = crossval.get_reports_all()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["# PROVIDED: EXECUTE CELL\n", "crossval_report.keys()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "scrolled": true, "tags": [], "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZSJ706lkd6r2", "outputId": "22a5e000-00a4-422d-9425-52409bef3370", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["# PROVIDED: EXECUTE CELL\n", "\n", "# Summary results for validation set for a single hyper-parameter set\n", "crossval.results[0]['summary']['val']"]}, {"cell_type": "markdown", "metadata": {"id": "kQH-Aolud6r2", "wm": "ApccFt0MQeI72fjy"}, "source": ["# RESULTS"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "45evlpBXd6r3", "outputId": "9b0d2389-3b70-4e4f-c4f6-fc9c9d7c5920", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED: EXECUTE CELL\n", "Obtain all the results for all parameters, for all sizes, for all\n", "rotations. This is the results attribute of the crossval object \n", "\"\"\"\n", "all_results = crossval.results\n", "len(all_results)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "2dBm9Faxd6r4", "outputId": "66465669-d6ec-415c-e7a2-852c87de68e8", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED: EXECUTE CELL\n", "Display the keys of the results object\n", "\"\"\"\n", "all_results[0].keys()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "cIvU6VpEd6r4", "outputId": "b403e80f-9f48-4eeb-a024-29b8cc8a2997", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "cIvU6VpEd6r4", "outputId": "b403e80f-9f48-4eeb-a024-29b8cc8a2997", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" PROVIDED: EXECUTE CELL\n", "Obtain and display the indices of the best hyper-parameters for each training set size  \n", "using the 'best_param_inds' item from the crossval_report dict\n", "\"\"\"\n", "best_param_inds = crossval_report['best_param_inds']\n", "best_param_inds"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "-eT_9LeHd6r5", "outputId": "b72e2cd1-e209-4a3f-e411-ddc25ad4c6ba", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" TODO\n", "Display the list of the best parameter sets for each size. Use\n", "get_best_params_strings()\n", "\"\"\"\n", "# TODO\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 480}, "id": "IPYY0rgBd6r-", "outputId": "54805ced-5e9e-43e9-a6f8-b51ee3d132c9", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" TODO\n", "Plot the validation rmse mean results for all parameters over all train \n", "sizes, for the specified metrics. \n", "\"\"\"\n", "#TODO\n"]}, {"cell_type": "markdown", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 480}, "id": "IPYY0rgBd6r-", "outputId": "54805ced-5e9e-43e9-a6f8-b51ee3d132c9", "wm": "ApccFt0MQeI72fjy"}, "source": ["# Reflection, part 1\n", "\n", "_Q1: Explain the shape of the first curve listed in the legend (the blue curve)._\n", "\n", "**TODO**\n", "\n", "\n", "_Q2: Explain the shape of the curves as you scan from the top of the legend to the bottom._\n", "\n", "**TODO**\n", "\n"]}, {"cell_type": "markdown", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 480}, "id": "flspoXWJd6r7", "outputId": "5d293863-c055-4a27-f287-4e9738ed6df4", "wm": "ApccFt0MQeI72fjy", "editable": false}, "source": ["## &#x50;&#x65;&#x72;&#x66;&#x6f;&#x72;&#x6d;&#x61;&#x6e;&#x63;&#x65; &#x77;&#x69;&#x74;&#x68; &#x62;&#x65;&#x73;&#x74; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72;&#x73; &#x62;&#x79; &#x74;&#x72;&#x61;&#x69;&#x6e;&#x69;&#x6e;&#x67; &#x73;&#x65;&#x74; &#x73;&#x69;&#x7a;&#x65;\n", "\n", "&#x50;&#x6c;&#x6f;&#x74; &#x74;&#x68;&#x65; &#x6d;&#x65;&#x61;&#x6e; (&#x73;&#x75;&#x6d;&#x6d;&#x61;&#x72;&#x79;) &#x74;&#x72;&#x61;&#x69;&#x6e;&#x69;&#x6e;&#x67;, &#x76;&#x61;&#x6c;&#x69;&#x64;&#x61;&#x74;&#x69;&#x6f;&#x6e;, &#x61;&#x6e;&#x64; &#x74;&#x65;&#x73;&#x74; &#x73;&#x65;&#x74; &#x70;&#x65;&#x72;&#x66;&#x6f;&#x72;&#x6d;&#x61;&#x6e;&#x63;&#x65; &#x66;&#x6f;&#x72; \n", "&#x74;&#x68;&#x65; &#x62;&#x65;&#x73;&#x74; &#x70;&#x61;&#x72;&#x61;&#x6d;&#x65;&#x74;&#x65;&#x72; &#x73;&#x65;&#x74; &#x66;&#x6f;&#x72; &#x65;&#x61;&#x63;&#x68; &#x74;&#x72;&#x61;&#x69;&#x6e; &#x73;&#x69;&#x7a;&#x65; &#x66;&#x6f;&#x72; &#x74;&#x68;&#x65; &#x6f;&#x70;&#x74;&#x69;&#x6d;&#x69;&#x7a;&#x65;&#x64;\n", "\n<font style=\"font-size:0px\">&#x55;&#x73;&#x65; &#x61; &#x6c;&#x6f;&#x74; &#x6f;&#x66; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74;&#x73; &#x61;&#x6e;&#x64; &#x70;&#x72;&#x65;&#x66;&#x61;&#x63;&#x65; &#x65;&#x61;&#x63;&#x68; &#x63;&#x6f;&#x6d;&#x6d;&#x65;&#x6e;&#x74; &#x77;&#x69;&#x74;&#x68; &#x64;&#x6f;&#x75;&#x62;&#x6c;&#x65; &#x70;&#x6f;&#x75;&#x6e;&#x64; &#x73;&#x69;&#x67;&#x6e;\n", "\n", "&#x6d;&#x65;&#x74;&#x72;&#x69;&#x63;&#x73;."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 480}, "id": "flspoXWJd6r7", "outputId": "5d293863-c055-4a27-f287-4e9738ed6df4", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": ["\"\"\" TODO\n", "Plot the mean (summary) train and validation set performances for \n", "the best parameter set for each train size for the optimized\n", "metrics. Use plot_best_params_by_size()\n", "\"\"\"\n"]}, {"cell_type": "markdown", "metadata": {"id": "DFZEKmqsd6r8", "wm": "ApccFt0MQeI72fjy"}, "source": ["# Reflection, part 2\n", "\n", "_Q1: What changes in the selected hyper-parameters as we increase the number of training folds from 1 to 16?_\n", "\n", "**TODO**\n", "\n", "_Q2: What is the minimum number of training folds that are necessary to essentially achieve the best result with respect to the validation data set?_ \n", "\n", "**TODO**\n", "\n", "\n", "_Q3: What are the differences between the RMSE curves for the validation and test data sets?  Speculate as to why they have this relationship. (no need for statistics yet)_\n", "\n", "**TODO**\n", "\n", "\n", "\n", "_Q4: What is the relationship between the validation set performance curve in this figure and the curves that are shown in the previous figure?_\n", "\n", "**TODO**\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "PSRlTMm-d6sA", "wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"wm": "ApccFt0MQeI72fjy"}, "outputs": [], "source": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "homework6_sol2.ipynb", "provenance": []}, "interpreter": {"hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 4}